{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:177.39285\n",
      "[50]\tvalidation_0-rmse:1.22115\n",
      "[100]\tvalidation_0-rmse:0.74382\n",
      "[150]\tvalidation_0-rmse:0.67076\n",
      "[200]\tvalidation_0-rmse:0.62989\n",
      "[250]\tvalidation_0-rmse:0.60207\n",
      "[300]\tvalidation_0-rmse:0.58509\n",
      "[350]\tvalidation_0-rmse:0.57449\n",
      "[400]\tvalidation_0-rmse:0.56476\n",
      "[450]\tvalidation_0-rmse:0.55079\n",
      "[500]\tvalidation_0-rmse:0.54652\n",
      "[550]\tvalidation_0-rmse:0.53922\n",
      "[600]\tvalidation_0-rmse:0.53111\n",
      "[650]\tvalidation_0-rmse:0.52652\n",
      "[700]\tvalidation_0-rmse:0.52220\n",
      "[750]\tvalidation_0-rmse:0.51790\n",
      "[800]\tvalidation_0-rmse:0.51623\n",
      "[850]\tvalidation_0-rmse:0.51129\n",
      "[900]\tvalidation_0-rmse:0.51039\n",
      "[950]\tvalidation_0-rmse:0.51179\n",
      "[999]\tvalidation_0-rmse:0.50765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Everything in one clode block\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import chardet\n",
    "\n",
    "color_pal = sns.color_palette()\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Function to detect file encoding\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "    return result['encoding']\n",
    "\n",
    "\n",
    "# Directories\n",
    "input_dir = 'data2'                 # Data2 is folder which only contains bus 1\n",
    "output_dir = 'results2'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Iterate over each file in the input directory\n",
    "for file_name in os.listdir(input_dir):\n",
    "    # Construct full file path\n",
    "    file_path = os.path.join(input_dir, file_name)\n",
    "    \n",
    "    # Check if it is a file\n",
    "    if os.path.isfile(file_path):\n",
    "        try:\n",
    "            # Detect the encoding of the file\n",
    "            encoding = detect_encoding(file_path)\n",
    "            \n",
    "            # Load the data from the file with detected encoding\n",
    "            df = pd.read_csv(file_path, encoding=encoding)\n",
    "\n",
    "            # Extract bus number from file name (assuming file name format is consistent)\n",
    "            bus_number = file_name.split('_')[1]\n",
    "            \n",
    "            # Create a subdirectory for each bus number\n",
    "            bus_dir = os.path.join(output_dir, f'bus_{bus_number}')\n",
    "            if not os.path.exists(bus_dir):\n",
    "                os.makedirs(bus_dir)\n",
    "\n",
    "\n",
    "\n",
    "            # 1. Read CSV file and set datetime index.\n",
    "            start_date = '01-01-2018'\n",
    "            datetime_index = pd.date_range(start=start_date, periods=len(df), freq='h')\n",
    "            df.index = datetime_index\n",
    "\n",
    "\n",
    "            # 2. Create time-based features.\n",
    "\n",
    "            # Feature creation\n",
    "            def create_features(df):\n",
    "                \"\"\"\n",
    "                Create time series features based on time series index.\n",
    "                \"\"\"\n",
    "                df = df.copy()\n",
    "                df['hour'] = df.index.hour\n",
    "                df['dayofweek'] = df.index.dayofweek\n",
    "                df['quarter'] = df.index.quarter\n",
    "                df['month'] = df.index.month\n",
    "                df['dayofyear'] = df.index.dayofyear\n",
    "                df['dayofmonth'] = df.index.day\n",
    "                return df\n",
    "\n",
    "            df = create_features(df)\n",
    "            \n",
    "\n",
    "            # 3. Lag features\n",
    "\n",
    "            def add_lags(df):\n",
    "                target_map = df['Load'].to_dict()\n",
    "\n",
    "                df['lag1'] = (df.index - pd.Timedelta('1 hour')).map(target_map)\n",
    "                df['lag24'] = (df.index - pd.Timedelta('24 hour')).map(target_map)\n",
    "                df['lag100'] = (df.index - pd.Timedelta('3 days')).map(target_map)\n",
    "                df['lag104'] = (df.index - pd.Timedelta('7 days')).map(target_map)\n",
    "                df['lag105'] = (df.index - pd.Timedelta('14 days')).map(target_map)\n",
    "                return df\n",
    "            df = add_lags(df)\n",
    "            \n",
    "\n",
    "            # 4. Prepare the data for training and validation.\n",
    "\n",
    "            # Review train/test split\n",
    "            train = df.loc[(df.index < '09-01-2018') | ((df.index >= '9-24-2018') & (df.index < '10-01-2018'))]           # Train including last 7 days before test start\n",
    "            validation = df.loc[(df.index >= '09-01-2018') & (df.index < '9-24-2018')]\n",
    "            test = df.loc[(df.index >= '10-01-2018')] # & (df.index < '12-31-2018')]     # Index 6554\n",
    "\n",
    "            \n",
    "\n",
    "            # Create the model\n",
    "            train = create_features(train)\n",
    "            validation = create_features(validation)\n",
    "            test = create_features(test)\n",
    "\n",
    "            FEATURES = ['lag104', 'lag1', 'lag24', 'lag100', 'lag105']\n",
    "            TARGET = 'Load'\n",
    "\n",
    "            X_train = train[FEATURES]\n",
    "            y_train = train[TARGET]\n",
    "\n",
    "            X_val = validation[FEATURES]\n",
    "            y_val = validation[TARGET]\n",
    "\n",
    "            X_test = test[FEATURES]\n",
    "            y_test = test[TARGET]\n",
    "\n",
    "            # Save the DataFrame as a CSV file in the bus subdirectory\n",
    "            csv_path = os.path.join(bus_dir, f'bus_{bus_number}_X_train.csv')\n",
    "            X_train.to_csv(csv_path, index=False)\n",
    "            csv_path = os.path.join(bus_dir, f'bus_{bus_number}_y_train.csv')\n",
    "            y_train.to_csv(csv_path, index=False)\n",
    "\n",
    "            csv_path = os.path.join(bus_dir, f'bus_{bus_number}_X_val.csv')\n",
    "            X_val.to_csv(csv_path, index=False)\n",
    "            csv_path = os.path.join(bus_dir, f'bus_{bus_number}_y_val.csv')\n",
    "            y_val.to_csv(csv_path, index=False)\n",
    "\n",
    "            csv_path = os.path.join(bus_dir, f'bus_{bus_number}_X_test.csv')\n",
    "            X_test.to_csv(csv_path, index=False)\n",
    "            csv_path = os.path.join(bus_dir, f'bus_{bus_number}_y_test.csv')\n",
    "            y_test.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "            # 5. Train the XGBoost model.\n",
    "\n",
    "\n",
    "\n",
    "            reg = xgb.XGBRegressor(base_score=0.5, booster='gbtree',    \n",
    "                                   n_estimators=1000,\n",
    "                                   early_stopping_rounds=50,\n",
    "                                   objective='reg:squarederror',\n",
    "                                   max_depth=3,                         # Used to be 3\n",
    "                                   learning_rate=0.1)                   # Used to be 0.01\n",
    "            reg.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=[(X_val, y_val)],      # Removed eval_metric='rmse'\n",
    "                verbose=50                      # Frequency of printing validation\n",
    "            )\n",
    "\n",
    "\n",
    "            # 6. Plot the actual vs predicted values.\n",
    "\n",
    "            # Feature importance\n",
    "            fi = pd.DataFrame(data=reg.feature_importances_,        # feature_importances_ is a standard function of \"reg\"\n",
    "                         index=reg.feature_names_in_,\n",
    "                         columns=['importance'])\n",
    "            \n",
    "            # fi.sort_values('importance').plot(kind='barh', title='Feature Importance')  # Sort by importance\n",
    "            # Save the plot as an image file in the bus subdirectory\n",
    "\n",
    "            ax = os.path.join(bus_dir, 'feature_importance_sorted.png')\n",
    "            plt.savefig(ax)\n",
    "            plt.clf()  # Clear the current figure to prevent overlap in the next iteration\n",
    "\n",
    "            # # Save the plot as an image file in the bus subdirectory\n",
    "            # plot_path = os.path.join(bus_dir, 'feature_importance')\n",
    "            # plt.savefig(plot_path)\n",
    "            # plt.clf()  # Clear the current figure to prevent overlap in the next iteration\n",
    "            \n",
    "            fi_sorted = fi.sort_values('importance', ascending=False)\n",
    "            csv_path = os.path.join(bus_dir, 'plotfeature_importance_sorted.csv')\n",
    "            fi.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "            # Plot everything\n",
    "            import pandas as pd\n",
    "            import os\n",
    "            from sklearn.metrics import mean_squared_error\n",
    "            import numpy as np\n",
    "            # Forecast on test\n",
    "            test['prediction'] = reg.predict(X_tes)\n",
    "            results = test[['Load', 'prediction']]  # Check this\n",
    "            csv_path = os.path.join(bus_dir, 'test_predictions.csv')\n",
    "            subset.to_csv(csv_path, index=True)\n",
    "\n",
    "            df = df.merge(test[['prediction']], how='left', left_index=True, right_index=True)\n",
    "            ax = df[['Load']].plot(figsize=(15, 5))\n",
    "            df['prediction'].plot(ax=ax, style='.')\n",
    "            plt.legend(['Truth Data', 'Predictions'])\n",
    "            ax.set_title('Raw Data and Prediction')\n",
    "            plot_path = os.path.join(bus_dir, 'plot_year.png')\n",
    "            plt.savefig(plot_path)\n",
    "            plt.clf()  # Clear the current figure to prevent overlap in the next iteration\n",
    "\n",
    "            # Calculate Mean Squared Error all year\n",
    "            score = np.sqrt(mean_squared_error(test['Load'], test['prediction']))**2\n",
    "            score_df = pd.DataFrame({'MSE': [score]})           # Create a DataFrame to store the score\n",
    "            csv_path = os.path.join(bus_dir, 'MSE_year.csv')\n",
    "            score_df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "            # Plot for 24 hours\n",
    "\n",
    "            # Define the date range for the plot\n",
    "            start_date = '2018-10-01'\n",
    "            end_date = '2018-10-02'\n",
    "\n",
    "            # Filter the data for the specified date range\n",
    "            subset = df.loc[(df.index > start_date) & (df.index < end_date)]\n",
    "\n",
    "            # Plot the Load data\n",
    "            ax = subset['Load'].plot(figsize=(15, 5), title='Predictions vs actual Load 1 okt 2018')\n",
    "\n",
    "            # Plot the Prediction data\n",
    "            subset['prediction'].plot(style='.', ax=ax)\n",
    "\n",
    "            # Set the legend\n",
    "            plt.legend(['Truth Data', 'Prediction'])\n",
    "\n",
    "            # Set the x-ticks and x-tick labels\n",
    "            xticks = subset.index[::1]  # For example, take every 6th index as a tick\n",
    "            ax.set_xticks(xticks)\n",
    "            ax.set_xticklabels(xticks.strftime('%H'), rotation=45, ha='right')     # ('%m-%d %H:%M')\n",
    "\n",
    "            # Set the x and y axis labels\n",
    "            ax.set_xlabel('Time in Hours')\n",
    "            ax.set_ylabel('Load (MW)')\n",
    "\n",
    "            # Save the plot as an image file in the bus subdirectory\n",
    "            ax = os.path.join(bus_dir, 'plot_24_hours.png')\n",
    "            plt.savefig(ax)\n",
    "            plt.clf()  # Clear the current figure to prevent overlap in the next iteration\n",
    "            \n",
    "\n",
    "            # plot_path = os.path.join(bus_dir, 'feature_importance')\n",
    "            # plt.savefig(plot_path)\n",
    "            # plt.clf()  # Clear the current figure to prevent overlap in the next iteration\n",
    "\n",
    "\n",
    "\n",
    "            # # Calculate Mean Squared Error 24 hours\n",
    "            # score = np.sqrt(mean_squared_error(test['Load'], test['prediction']))**2\n",
    "            # score_df = pd.DataFrame({'MSE': [score]})           # Create a DataFrame to store the score\n",
    "            # bus_dir = '.'                                       # Update this to your actual directory path if different\n",
    "            # csv_path = os.path.join(bus_dir, 'MSE_24_hours.csv')\n",
    "            # score_df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "            # # Save the plot as an image file in the bus subdirectory\n",
    "            # plot_path = os.path.join(bus_dir, 'plot.png')\n",
    "            # plt.savefig(plot_path)\n",
    "            # plt.clf()  # Clear the current figure to prevent overlap in the next iteration\n",
    "            \n",
    "            # # Save the DataFrame as a CSV file in the bus subdirectory\n",
    "            # csv_path = os.path.join(bus_dir, f'bus_{bus_number}_data.csv')\n",
    "            # df.to_csv(csv_path, index=False)\n",
    "            \n",
    "            # ax = df.loc[(df.index > '10-01-2018') & (df.index < '10-04-2018')]['Load'] \\\n",
    "            #     .plot(figsize=(15, 5), title='3 days of data')\n",
    "            # df.loc[(df.index > '10-01-2018') & (df.index < '10-04-2018')]['prediction'] \\\n",
    "            #     .plot(style='.')\n",
    "            # plt.legend(['Truth Data','Prediction'])\n",
    "\n",
    "            # # Save the plot as an image file in the bus subdirectory\n",
    "            # plot_path = os.path.join(bus_dir, 'plot_3_days.png')\n",
    "            # plt.savefig(plot_path)\n",
    "            # plt.clf()  # Clear the current figure to prevent overlap in the next iteration\n",
    "\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_name}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
